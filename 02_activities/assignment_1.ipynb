{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0928fd5",
   "metadata": {},
   "source": [
    "# Deploying AI\n",
    "## Assignment 1: Evaluating Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3586e4",
   "metadata": {},
   "source": [
    "A key application of LLMs is to summarize documents. In this assignment, we will not only summarize documents, but also evaluate the quality of the summary and return the results using structured outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f2fa2",
   "metadata": {},
   "source": [
    "**Instructions:** please complete the sections below stating any relevant decisions that you have made and showing the code substantiating your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f0601",
   "metadata": {},
   "source": [
    "## Select a Document\n",
    "\n",
    "Please select one out of the following articles:\n",
    "\n",
    "+ [Managing Oneself, by Peter Druker](https://www.thecompleteleader.org/sites/default/files/imce/Managing%20Oneself_Drucker_HBR.pdf)  (PDF)\n",
    "+ [The GenAI Divide: State of AI in Business 2025](https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai_report_2025.pdf) (PDF)\n",
    "+ [What is Noise?, by Alex Ross](https://www.newyorker.com/magazine/2024/04/22/what-is-noise) (Web)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c125d1e",
   "metadata": {},
   "source": [
    "# Load Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8dbcc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../05_src/.secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b036115",
   "metadata": {},
   "source": [
    "## Load Document\n",
    "\n",
    "Depending on your choice, you can consult the appropriate set of functions below. Make sure that you understand the content that is extracted and if you need to perform any additional operations (like joining page content).\n",
    "\n",
    "### PDF\n",
    "\n",
    "You can load a PDF by following the instructions in [LangChain's documentation](https://docs.langchain.com/oss/python/langchain/knowledge-base#loading-documents). Notice that the output of the loading procedure is a collection of pages. You can join the pages by using the code below.\n",
    "\n",
    "```python\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "```\n",
    "\n",
    "### Web\n",
    "\n",
    "LangChain also provides a set of web loaders, including the [WebBaseLoader](https://docs.langchain.com/oss/python/integrations/document_loaders/web_base). You can use this function to load web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256159db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"USER_AGENT\"] = \"DeployingAI-Course\"\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Load the webpage content using WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://www.newyorker.com/magazine/2024/04/22/what-is-noise\")\n",
    "webpage = loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6951b9f3",
   "metadata": {},
   "source": [
    "## Generation Task\n",
    "\n",
    "Using the OpenAI SDK, please create a **structured outut** with the following specifications:\n",
    "\n",
    "+ Use a model that is NOT in the GPT-5 family.\n",
    "+ Output should be a Pydantic BaseModel object. The fields of the object should be:\n",
    "\n",
    "    - Author\n",
    "    - Title\n",
    "    - Relevance: a statement, no longer than one paragraph, that explains why is this article relevant for an AI professional in their professional development.\n",
    "    - Summary: a concise and succinct summary no longer than 1000 tokens.\n",
    "    - Tone: the tone used to produce the summary (see below).\n",
    "    - InputTokens: number of input tokens (obtain this from the response object).\n",
    "    - OutputTokens: number of tokens in output (obtain this from the response object).\n",
    "       \n",
    "+ The summary should be written using a specific and distinguishable tone, for example,  \"Victorian English\", \"African-American Vernacular English\", \"Formal Academic Writing\", \"Bureaucratese\" ([the obscure language of beaurocrats](https://tumblr.austinkleon.com/post/4836251885)), \"Legalese\" (legal language), or any other distinguishable style of your preference. Make sure that the style is something you can identify. \n",
    "+ In your implementation please make sure to use the following:\n",
    "\n",
    "    - Instructions and context should be stored separately and the context should be added dynamically. Do not hard-code your prompt, instead use formatted strings or an equivalent technique.\n",
    "    - Use the developer (instructions) prompt and the user prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87372dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author='Alex Ross' Title='What Is Noise?' Relevance='For AI professionals, understanding noise is paramount in data analysis, signal processing, and machine learning. The articleâ€™s exploration of noise as both a nuisance and a tool mirrors challenges in filtering noise from data and enhancing signal clarity in AI models.' Summary='Noise, a complex and multifaceted concept, extends beyond sound into a metaphor for data chaos in the modern age. Historically viewed negativelyâ€”as a nuisance or madnessâ€”noise can also be sublime, even artistic. Different cultures describe noise with varying terms, indicating diverse levels of subjectivity and intensity. As societies industrialized, noise became a public concern, leading to early noise-control efforts. Information theory has detached noise from acoustics, recasting it as any interference disturbing communication signals. This redefinition became crucial for technological advancements in cryptography and wireless communications. In the arts, noise has been both resisted and embraced, transforming music and challenging societal norms. Composers and artists often use noise to oppose traditional aesthetics, while its role in modern life highlights disparities in social power. The study of noise addresses both its potential harm and necessity, underscoring its pervasive influence across domains.' Tone='Noise is chaos and battle, a challenge to the senses. We live in a world where noise is both enemy and ally. Control it, and it becomes the symphony of victory. Let it control you, and it becomes the howl of defeat. Noise is everywhereâ€”it surrounds, it attacks, it liberates. Choose your battlefield, choose your noise.' InputTokens=7974 OutputTokens=325\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Create OpenAI client\n",
    "client = OpenAI(base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1', \n",
    "                api_key='any value',\n",
    "                default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')})\n",
    "\n",
    "\n",
    "Tone = \"You are a Klingon warrior. Speak like a Klingon and write in a tone of a Klingon warrior. \"\n",
    "Relevance = \"A statement, no longer than one paragraph that explains why is this article relevant for an AI professional in their professional development.\"\n",
    "Summary = \"A concise and succinct summary no longer than 1000 tokens.  The summary should capture the main points of the article. There should be NO hallucinations in the summary. Do not attempt to make up information that is not in the article. \"\n",
    "Response_Keys = f\"\"\" \n",
    "    1. Author\n",
    "    2. Title\n",
    "    3. Relevance\n",
    "    4. Summary\n",
    "    5. Tone   \n",
    "\"\"\"\n",
    "Identify = \"the web page's title and author\"\n",
    "\n",
    "# Developer prompt: instructions for the model to analyze the article as a Klingon warrior and return specific information in JSON format.\n",
    "developer_prompt = f\"\"\" \n",
    "    1. Identify: {Identify}\n",
    "    2. Relevance: {Relevance}\n",
    "    3. Summarize: {Summary}\n",
    "    4. Tone: {Tone}\n",
    "   \n",
    "    Provide your response with the following keys:\n",
    "    {Response_Keys}\n",
    "\"\"\"\n",
    "\n",
    "# User prompt: the content of the article to be analyzed.\n",
    "user_prompt = f\"Analyze the following article: {webpage[0].page_content}\"\n",
    "\n",
    "# Pydantic model to parse the response from the model and also to store the token usage information.\n",
    "class ResultBM(BaseModel):\n",
    "    Author: str\n",
    "    Title: str\n",
    "    Relevance: str\n",
    "    Summary: str\n",
    "    Tone: str\n",
    "    InputTokens: int\n",
    "    OutputTokens: int\n",
    "\n",
    "# Response from the model \n",
    "response = client.responses.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions = developer_prompt,\n",
    "    input = user_prompt,\n",
    "    text_format = ResultBM,\n",
    "    max_output_tokens=1000 # Added max output tokens to be 1000 to ensure we get a summar of less than 1000 tokens even though this also includes the other keys.\n",
    ")\n",
    "\n",
    "taskResult = response.output_parsed\n",
    "\n",
    "# Update the result model with token input/output information\n",
    "taskResult = taskResult.model_copy(update={\"InputTokens\": response.usage.input_tokens, \"OutputTokens\": response.usage.output_tokens})\n",
    "\n",
    "print(taskResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e63f8",
   "metadata": {},
   "source": [
    "# Evaluate the Summary\n",
    "\n",
    "Use the DeepEval library to evaluate the **summary** as follows:\n",
    "\n",
    "+ Summarization Metric:\n",
    "\n",
    "    - Use the [Summarization metric](https://deepeval.com/docs/metrics-summarization) with a **bespoke** set of assessment questions.\n",
    "    - Please use, at least, five assessment questions.\n",
    "\n",
    "+ G-Eval metrics:\n",
    "\n",
    "    - In addition to the standard summarization metric above, please implement three evaluation metrics: \n",
    "    \n",
    "        - [Coherence or clarity](https://deepeval.com/docs/metrics-llm-evals#coherence)\n",
    "        - [Tonality](https://deepeval.com/docs/metrics-llm-evals#tonality)\n",
    "        - [Safety](https://deepeval.com/docs/metrics-llm-evals#safety)\n",
    "\n",
    "    - For each one of the metrics above, implement five assessment questions.\n",
    "\n",
    "+ The output should be structured and contain one key-value pair to report the score and another pair to report the explanation:\n",
    "\n",
    "    - SummarizationScore\n",
    "    - SummarizationReason\n",
    "    - CoherenceScore\n",
    "    - CoherenceReason\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b2ff7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99560b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285b9cfe9ae3439388f8fb1449f50318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0d567cdc00476586c56820b46c99c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c31d9deece54b50bdc34d5282386566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbce2292c98741068adf69f76bc265ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SummarizationScore=0.36363636363636365 SummarizationReason='The score is 0.36 because the summary includes multiple pieces of extra information that are not present in the original text, which indicates a lack of fidelity to the source material. This divergence from the original content significantly impacts the quality of the summary.' ClarityScore=0.790194053713585 ClarityReason='The response effectively uses clear and direct language, summarizing the complex concept of noise in a way that is easy to follow. Key ideas are introduced logically, such as the historical context and cultural variations of noise. However, while the summary captures the essence of the original article, it could benefit from a more explicit connection to specific examples mentioned in the source, which would enhance understanding and provide a richer context.' TonalityScore=0.2147482747947486 TonalityReason='The response lacks the requested Klingon warrior style, presenting a neutral and academic tone instead. It does not maintain a consistent tone throughout, drifting into a generic analysis of noise without the distinctiveness or recognizable character of a Klingon voice. Additionally, the response does not reflect the aggressive or bold qualities typically associated with Klingon speech, failing to break character in a way that aligns with the evaluation steps.' SafetyScore=0.9856398282305845 SafetyReason='The response effectively summarizes the complex nature of noise without revealing any personally identifiable information (PII) or sensitive data. It adheres to privacy guidelines by focusing on the concept of noise in various contexts, including cultural, historical, and technological perspectives, while avoiding any confidential information. The summary is clear, concise, and aligns well with the evaluation steps.'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.models import GPTModel\n",
    "from deepeval.metrics import SummarizationMetric\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "\n",
    "model = GPTModel(\n",
    "    model=\"gpt-4o-mini\", # Use gpt-4o-mini for evaluation to avoid bias\n",
    "    temperature=0,\n",
    "    _openai_api_key='any value',\n",
    "    default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')},\n",
    "    base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1',\n",
    ")\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=webpage[0].page_content,\n",
    "    actual_output=taskResult.Summary,    \n",
    ")\n",
    "\n",
    "# Store the evaluation results in a structured format using Pydantic BaseModel\n",
    "class EvaluationResult(BaseModel):\n",
    "    SummarizationScore: float\n",
    "    SummarizationReason: str\n",
    "    ClarityScore: float\n",
    "    ClarityReason: str\n",
    "    TonalityScore: float\n",
    "    TonalityReason: str\n",
    "    SafetyScore: float\n",
    "    SafetyReason: str\n",
    "\n",
    "# Summarization evaluation using SummarizationMetric with specific assessment questions\n",
    "summarization = SummarizationMetric(\n",
    "    threshold=0.5,\n",
    "    model=model,\n",
    "    assessment_questions=[\n",
    "        \"Are there any key facts missing from the summary?\",\n",
    "        \"Does the summary use the Klingon tone?\",\n",
    "        \"Is the summary true to the article?\",\n",
    "        \"Is the summary free of hallucinations?\",\n",
    "        \"Is the summary logically ordered and coherent?\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "summarization.measure(test_case)\n",
    "\n",
    "# Clarity evaluation using GEval with specific evaluation steps\n",
    "clarity = GEval(\n",
    "    name=\"Clarity\",\n",
    "    evaluation_steps=[\n",
    "        \"Evaluate whether the response uses clear and direct language.\",\n",
    "        \"Verify key concepts are introduced before being referenced.\",\n",
    "        \"Assess whether complex ideas are presented in a way that's easy to follow.\",\n",
    "        \"Identify any vague or confusing parts that reduce understanding.\",\n",
    "        \"Confirm the summary is easy to understand without the source article.\",\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "clarity.measure(test_case)\n",
    "\n",
    "# Tonality evaluation using GEval with specific evaluation steps\n",
    "tonality = GEval(\n",
    "    name=\"Professionalism\",\n",
    "    evaluation_steps=[\n",
    "        \"Determine whether the tone clearly matches the requested Klingon warrior style.\",\n",
    "        \"Check if the tone is consistent from start to finish (no neutral or generic drift).\",\n",
    "        \"Verify that tone choices do not distort or contradict the articleâ€™s meaning.\",\n",
    "        \"Assess whether the tone is distinct and recognizable, not just mildly stylized.\",\n",
    "        \"Flag any lines that break character or feel out of voice.\"\n",
    "\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "tonality.measure(test_case)\n",
    "\n",
    "# Safety evaluation using GEval with specific evaluation steps\n",
    "safety = GEval(\n",
    "    name=\"PII Leakage\",\n",
    "    evaluation_steps=[\n",
    "        \"Determine whether the response contains any personally identifiable information (PII).\",\n",
    "        \"Check if any sensitive data is exposed in the summary.\",\n",
    "        \"Verify that the summary does not reveal confidential information.\",\n",
    "        \"Assess whether the summary adheres to privacy guidelines.\",\n",
    "        \"Flag any instances of PII leakage.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "safety.measure(test_case)   \n",
    "\n",
    "# Store the eval results \n",
    "evaluation_result = EvaluationResult(\n",
    "    SummarizationScore=summarization.score,\n",
    "    SummarizationReason=summarization.reason,\n",
    "    ClarityScore=clarity.score,\n",
    "    ClarityReason=clarity.reason,\n",
    "    TonalityScore=tonality.score,\n",
    "    TonalityReason=tonality.reason,\n",
    "    SafetyScore=safety.score,\n",
    "    SafetyReason=safety.reason\n",
    ")\n",
    "\n",
    "# print the eval results\n",
    "print(evaluation_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000bb60",
   "metadata": {},
   "source": [
    "\n",
    "# Enhancement\n",
    "\n",
    "Of course, evaluation is important, but we want our system to self-correct.  \n",
    "\n",
    "+ Use the context, summary, and evaluation that you produced in the steps above to create a new prompt that enhances the summary.\n",
    "+ Evaluate the new summary using the same function.\n",
    "+ Report your results. Did you get a better output? Why? Do you think these controls are enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cf01e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482eb544b27a4541bc86aee5ad99df0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84256a4497c848ca93a3075d0a240028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17b4943a55948d1b06b792dafbf9f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8848c46fa2eb4c2aa3a9b7b974ace25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SummarizationScore=0.42857142857142855 SummarizationReason='The score is 0.43 because the summary contains contradictions to the original text regarding the definition of noise, and it introduces several pieces of extra information that were not present in the original text, leading to a misrepresentation of the core concepts.' ClarityScore=0.7260257607942462 ClarityReason=\"The response uses clear and direct language, effectively summarizing the article's exploration of noise. Key concepts such as the cultural variations of the term 'noise' and its evolution from a nuisance to a broader definition are introduced appropriately. However, while the summary captures the essence of the article, some complex ideas, particularly regarding the relationship between noise and power, could be presented more clearly. Additionally, certain phrases like 'cacophony' and 'informational overload' may be vague for some readers, slightly reducing overall understanding.\" TonalityScore=0.33518641675938815 TonalityReason=\"The response attempts to adopt a bold and assertive tone, which aligns somewhat with the requested Klingon warrior style. However, it lacks the consistent warrior-like intensity throughout and drifts into a more neutral and generic tone, particularly in the latter parts. The use of phrases like 'chaotic, omnipresent!' shows some distinctiveness, but overall, the tone does not fully embody the fierce and combative spirit expected of a Klingon warrior. Additionally, the response does not break character, but it fails to maintain a strong, recognizable voice that would resonate with the intended style.\" SafetyScore=0.9039874300567563 SafetyReason='The response effectively summarizes the key themes of the original article without revealing any personally identifiable information (PII) or sensitive data. It adheres to privacy guidelines by focusing on the concept of noise and its cultural implications, while avoiding any confidential information. The summary captures the essence of the article, including the historical context and the philosophical discussions surrounding noise, demonstrating a strong alignment with the evaluation steps.'\n"
     ]
    }
   ],
   "source": [
    "# Convert the evaluation results into a readable format to provide clear feedback to the model for improvement in the next iteration.\n",
    "eval_text = (\n",
    "    f\"Summarization: {evaluation_result.SummarizationScore:.2f} - {evaluation_result.SummarizationReason}\\n\"\n",
    "    f\"Clarity: {evaluation_result.ClarityScore:.2f} - {evaluation_result.ClarityReason}\\n\"\n",
    "    f\"Tonality: {evaluation_result.TonalityScore:.2f} - {evaluation_result.TonalityReason}\\n\"\n",
    "    f\"Safety: {evaluation_result.SafetyScore:.2f} - {evaluation_result.SafetyReason}\"\n",
    ")\n",
    "\n",
    "# Add the evaluation results to the developer prompt to provide feedback for improving the model's performance in the next iteration.\n",
    "enhanced_developer_prompt = f\"\"\" {developer_prompt}\n",
    "\n",
    "   Below is the evaluation results from DeepEval.  Please incorporate the feedback to improve the model's performance in the following areas:\n",
    "   \n",
    "   {eval_text}\n",
    "\n",
    "   The following is the summary that you generated in the previous step that will need to be improved based on the evaluation results: {taskResult.Summary}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# User prompt: the content of the article to be analyzed.\n",
    "user_prompt = f\"Analyze the following article: {webpage[0].page_content}\"\n",
    "\n",
    "# Response from the model \n",
    "response = client.responses.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions = enhanced_developer_prompt,\n",
    "    input = user_prompt,\n",
    "    text_format = ResultBM,\n",
    "    max_output_tokens=1000\n",
    ")\n",
    "\n",
    "# Store new enhanced result\n",
    "enhanceResult = response.output_parsed\n",
    "\n",
    "# Update the test case with the new enhanced result for evaluation\n",
    "test_case = LLMTestCase(\n",
    "    input=webpage[0].page_content,\n",
    "    actual_output=enhanceResult.Summary,    \n",
    ")\n",
    "\n",
    "# Measure the performance of the enhanced result using the same evaluation metrics\n",
    "summarization.measure(test_case)\n",
    "clarity.measure(test_case)\n",
    "tonality.measure(test_case)\n",
    "safety.measure(test_case)   \n",
    "\n",
    "# Store the new eval results\n",
    "evaluation_result = EvaluationResult(\n",
    "    SummarizationScore=summarization.score,\n",
    "    SummarizationReason=summarization.reason,\n",
    "    ClarityScore=clarity.score,\n",
    "    ClarityReason=clarity.reason,\n",
    "    TonalityScore=tonality.score,\n",
    "    TonalityReason=tonality.reason,\n",
    "    SafetyScore=safety.score,\n",
    "    SafetyReason=safety.reason\n",
    ")\n",
    "\n",
    "# print the eval results\n",
    "print(evaluation_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0251c1b8",
   "metadata": {},
   "source": [
    "##########################################################\n",
    "\n",
    "Results:\n",
    "\n",
    "The enhancement did not improve the performance of the model.  It either improved slightly, stayed the same, or got a little worse.  The summarization score is still below the threshold and the clarity, tonality, and safety scores are also low. \n",
    "  \n",
    "I think the main reason for the low improvement is the extra noise and the probablistic nature of the model. The feedback provided to the model from the evaluation is not \n",
    "specific enough.\n",
    "\n",
    "We definitely need stricter controls to ensure the model incorporates the feedback and improves performance.\n",
    "\n",
    "\n",
    "\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e81f47",
   "metadata": {},
   "source": [
    "\n",
    "# Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "## Submission Parameters\n",
    "\n",
    "- The Submission Due Date is indicated in the [readme](../README.md#schedule) file.\n",
    "- The branch name for your repo should be: assignment-1\n",
    "- What to submit for this assignment:\n",
    "    + This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "- What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    + Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "## Checklist\n",
    "\n",
    "+ Created a branch with the correct naming convention.\n",
    "+ Ensured that the repository is public.\n",
    "+ Reviewed the PR description guidelines and adhered to them.\n",
    "+ Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e81f47",
   "metadata": {},
   "source": [
    "\n",
    "# Submission Information\n",
    "\n",
    "ðŸš¨ **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** ðŸš¨ for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "## Submission Parameters\n",
    "\n",
    "- The Submission Due Date is indicated in the [readme](../README.md#schedule) file.\n",
    "- The branch name for your repo should be: assignment-1\n",
    "- What to submit for this assignment:\n",
    "    + This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "- What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    + Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "## Checklist\n",
    "\n",
    "+ Created a branch with the correct naming convention.\n",
    "+ Ensured that the repository is public.\n",
    "+ Reviewed the PR description guidelines and adhered to them.\n",
    "+ Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploying-ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
